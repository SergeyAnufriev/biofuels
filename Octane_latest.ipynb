{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4d6326",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Octane modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "'''custom modules'''\n",
    "from filter_data import Select_descriptors\n",
    "from process_data import Scalar\n",
    "from simmilarity import mean_tanimato,Leverage\n",
    "from train import Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\zcemg08\\Desktop\\phys_data\\octane_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Data preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### 1.1 Remove columns with missing values\n",
    "misssing_val_cols = df.columns[df.isnull().any()]\n",
    "print('Columns with missing values are = {}'.format(list(misssing_val_cols)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### 1.2 Remove columns with irrelevant to modelling values\n",
    "df_ = df.drop(misssing_val_cols,axis=1)\n",
    "\n",
    "irrelevant_to_pred_columns = ['PubChem','ron_choice']\n",
    "\n",
    "df_ = df_.drop(irrelevant_to_pred_columns,axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('final dataset sie = {}'.format(df_.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Split dataset (standartization must be applied on train set only )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 42 # Fix random seed to make split reproducible (experiment must be reproducible)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_.drop('y',axis=1), df_['y'], test_size=0.2, random_state=seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Train dataset size = {}'.format(X_train.shape))\n",
    "print('Test dataset size = {}'.format(X_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normilise features, so varince threshold can be applied\n",
    "sc         = Scalar('minmax')\n",
    "\n",
    "# Wrapper feature selector\n",
    "wrapper    = sfs(SVR(gamma='auto'),\n",
    "              n_features_to_select=50,\n",
    "              scoring='neg_mean_squared_error',\n",
    "              cv=5)\n",
    "\n",
    "# Applies varience threshold, removes high correlated features, removes higly skewed vars and applies wrapper in the end.\n",
    "\n",
    "Filter_    = Select_descriptors(0.01,0.95,None,wrapper)\n",
    "\n",
    "sc.fit(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train  = Filter_.transform(sc.transform(X_train),y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ml_model = Model('SVM',X_train,y_train,120)\n",
    "\n",
    "model_   = ml_model.build_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Performance on the test set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate prediction errors\n",
    "y_pred_test = model_.predict(sc.transform(X_test)[X_train.columns[1:]])\n",
    "mae         = np.abs(y_test.values-y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(y_pred_test,y_test)\n",
    "plt.plot(np.linspace(0,130,10),np.linspace(0,130,10))\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('expected')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_error = pd.DataFrame(columns=['SMILES','MAE'])\n",
    "data_error['SMILES'] = X_test.iloc[np.where(mae>20)[0]]['SMILES'].values\n",
    "data_error['MAE'] = mae[np.where(mae>20)[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Applicability domain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. OneClassSVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_inside = []\n",
    "\n",
    "for nu in np.linspace(0.001,0.99,20):\n",
    "\n",
    "    clf = OneClassSVM(nu=nu, kernel=\"rbf\", gamma=0.1)\n",
    "    clf.fit(X_train.values[:,1:])\n",
    "    label = clf.predict(sc.transform(X_test)[X_train.columns[1:]])\n",
    "    mean_inside.append(mae[np.where(label>0)[0]].mean())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0.001,0.99,20),mean_inside)\n",
    "plt.xlabel('mu')\n",
    "plt.ylabel('MAE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.Tanimato distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DM = mean_tanimato\n",
    "Tanimato_dist = X_test['SMILES'].apply(lambda x: DM(x,X_train)).values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(Tanimato_dist,mae)\n",
    "plt.xlabel('Mean tanimato distance')\n",
    "plt.ylabel('MAE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spread_tanimato = Tanimato_dist.max() - Tanimato_dist.min()\n",
    "\n",
    "mean_inside2 = []\n",
    "for i in range(1,20):\n",
    "    upper_bound = Tanimato_dist.max() - i*spread_tanimato/20\n",
    "    mean_inside2.append(mae[np.where(Tanimato_dist<upper_bound)[0]].mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,1,19),mean_inside2)\n",
    "plt.xlabel('Fraction')\n",
    "plt.ylabel('MAE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def box_plot(dist,mae):\n",
    "\n",
    "    df_  = pd.DataFrame(np.vstack((dist,mae)).T,columns=['dist','MAE'])\n",
    "    bins = pd.cut(df_.iloc[:,0], list(np.linspace(dist.max(), dist.min(), 5))[::-1])\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.boxplot([g[1] for g in df_.groupby(bins)['MAE']])\n",
    "    ax.set_xticklabels(str(g[0])[1:-1] for g in df_.groupby(bins)['MAE'])\n",
    "    ax.set_xlabel('distance bins')\n",
    "    ax.set_ylabel('MAE')\n",
    "\n",
    "    fig.tight_layout()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "box_plot(Tanimato_dist,mae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Leaverage distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_test_normed = sc.transform(X_test)[X_train.columns].values[:,1:]\n",
    "lev_dist      = [Leverage(x_test_normed[i,:],X_train.values[:,1:]) for i in range(len(X_test))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(lev_dist,mae)\n",
    "plt.xlabel('Leaverage distance')\n",
    "plt.ylabel('MAE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "box_plot(np.array(lev_dist),mae)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Isolation forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_inside = []\n",
    "\n",
    "for cont in np.linspace(0.001,0.99,20):\n",
    "\n",
    "    clf = IsolationForest(n_estimators=100, max_samples='auto', contamination=cont,\n",
    "                          max_features=1.0, bootstrap=False, n_jobs=-1, random_state=42, verbose=0)\n",
    "    clf.fit(X_train.values[:,1:])\n",
    "    label = clf.predict(sc.transform(X_test)[X_train.columns[1:]])\n",
    "    mean_inside.append(mae[np.where(label>0)[0]].mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0.001,0.99,20),mean_inside)\n",
    "plt.xlabel('contamination %')\n",
    "plt.ylabel('MAE')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biofuel",
   "language": "python",
   "name": "biofuel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}